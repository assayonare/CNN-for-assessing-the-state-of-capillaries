{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/assayonare/CNN-for-assessing-the-state-of-capillaries/blob/main/capillaroscopy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeMpJoTEHXTk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "import os\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jy36YUufjI5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def merge_overlapping_boxes(boxes, overlapThresh=0.3):\n",
        "    \"\"\"\n",
        "    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è –±–æ–∫—Å—ã.\n",
        "    –ö–∞–∂–¥—ã–π –±–æ–∫—Å –∑–∞–¥–∞–µ—Ç—Å—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ (x, y, w, h).\n",
        "    \"\"\"\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±–æ–∫—Å—ã –≤ —Ñ–æ—Ä–º–∞—Ç (x1, y1, x2, y2)\n",
        "    boxes_arr = np.array([[x, y, x+w, y+h] for (x, y, w, h) in boxes])\n",
        "    merged = True\n",
        "    while merged:\n",
        "        merged = False\n",
        "        new_boxes = []\n",
        "        used = np.zeros(len(boxes_arr), dtype=bool)\n",
        "\n",
        "        for i in range(len(boxes_arr)):\n",
        "            if used[i]:\n",
        "                continue\n",
        "            # –¢–µ–∫—É—â–∏–π –±–æ–∫—Å\n",
        "            current_box = boxes_arr[i].copy()\n",
        "            for j in range(i+1, len(boxes_arr)):\n",
        "                if used[j]:\n",
        "                    continue\n",
        "                box = boxes_arr[j]\n",
        "                # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ\n",
        "                xx1 = max(current_box[0], box[0])\n",
        "                yy1 = max(current_box[1], box[1])\n",
        "                xx2 = min(current_box[2], box[2])\n",
        "                yy2 = min(current_box[3], box[3])\n",
        "                w = max(0, xx2 - xx1)\n",
        "                h = max(0, yy2 - yy1)\n",
        "                inter = w * h\n",
        "                area_current = (current_box[2]-current_box[0]) * (current_box[3]-current_box[1])\n",
        "                area_box = (box[2]-box[0]) * (box[3]-box[1])\n",
        "                iou = inter / float(area_current + area_box - inter)\n",
        "                if iou > overlapThresh:\n",
        "                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–æ–∫—Å—ã\n",
        "                    current_box[0] = min(current_box[0], box[0])\n",
        "                    current_box[1] = min(current_box[1], box[1])\n",
        "                    current_box[2] = max(current_box[2], box[2])\n",
        "                    current_box[3] = max(current_box[3], box[3])\n",
        "                    used[j] = True\n",
        "                    merged = True\n",
        "            new_boxes.append(current_box)\n",
        "            used[i] = True\n",
        "        boxes_arr = np.array(new_boxes)\n",
        "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ (x, y, w, h)\n",
        "    return [(int(x1), int(y1), int(x2-x1), int(y2-y1)) for x1, y1, x2, y2 in boxes_arr]\n",
        "\n",
        "\n",
        "# –ó–∞–¥–∞—ë–º –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –æ–∂–∏–¥–∞–µ—Ç –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, 64x64)\n",
        "input_size = (64, 64)\n",
        "\n",
        "# 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–ø–∏–ª–ª—è—Ä–æ–≤ –≤ –æ—Ç—Ç–µ–Ω–∫–∞—Ö —Å–µ—Ä–æ–≥–æ\n",
        "image = cv2.imread(\"/content/drive/MyDrive/inp/image_capillar (13).png\", cv2.IMREAD_GRAYSCALE)\n",
        "if image is None:\n",
        "    raise Exception(\"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ!\")\n",
        "\n",
        "# 3. –£–ª—É—á—à–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —à—É–º–∞, –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü –∏ –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤\n",
        "blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
        "edges = cv2.Canny(blurred, 50, 150)\n",
        "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 20]\n",
        "\n",
        "# 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º bounding boxes (–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ —Ä–∞–º–∫–∏) —Å –æ—Ç—Å—Ç—É–ø–æ–º\n",
        "padding = 30  # —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–º–∫–∏\n",
        "boxes = []\n",
        "for cnt in filtered_contours:\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    x_new = max(0, x - padding)\n",
        "    y_new = max(0, y - padding)\n",
        "    w_new = min(image.shape[1] - x_new, w + 2 * padding)\n",
        "    h_new = min(image.shape[0] - y_new, h + 2 * padding)\n",
        "    boxes.append((x_new, y_new, w_new, h_new))\n",
        "\n",
        "# 5. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è bounding boxes –ø–æ —Ü–µ–Ω—Ç—Ä–∞–º (DBSCAN)\n",
        "box_centers = [(x + w // 2, y + h // 2) for x, y, w, h in boxes]\n",
        "X = np.array(box_centers)\n",
        "dbscan = DBSCAN(eps=35, min_samples=1).fit(X)\n",
        "clustered_boxes = {}\n",
        "for label, box in zip(dbscan.labels_, boxes):\n",
        "    if label not in clustered_boxes:\n",
        "        clustered_boxes[label] = []\n",
        "    clustered_boxes[label].append(box)\n",
        "\n",
        "# 6. –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ bounding boxes –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞\n",
        "final_boxes = []\n",
        "for cluster in clustered_boxes.values():\n",
        "    x_min = min(x for x, y, w, h in cluster)\n",
        "    y_min = min(y for x, y, w, h in cluster)\n",
        "    x_max = max(x + w for x, y, w, h in cluster)\n",
        "    y_max = max(y + h for x, y, w, h in cluster)\n",
        "    final_boxes.append((x_min, y_min, x_max - x_min, y_max - y_min))\n",
        "\n",
        "# 7. –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ, —á—Ç–æ–±—ã –±–æ–∫—Å—ã –Ω–µ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–ª–∏—Å—å\n",
        "final_boxes = merge_overlapping_boxes(final_boxes, overlapThresh=0.3)\n",
        "\n",
        "# 8. –ì–æ—Ç–æ–≤–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BGR, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –Ω–∞–ª–æ–∂–∏—Ç—å —Ü–≤–µ—Ç–Ω–æ–µ –≤—ã–¥–µ–ª–µ–Ω–∏–µ)\n",
        "image_with_overlay = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# 9. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞:\n",
        "#    - –ò–∑–≤–ª–µ–∫–∞–µ–º ROI, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–æ input_size, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏.\n",
        "#    - –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–ª–∞—Å—Å 0 (–¥–µ—Ñ–µ–∫—Ç–Ω—ã–π), –≤—ã–¥–µ–ª—è–µ–º –æ–±–ª–∞—Å—Ç—å –∫—Ä–∞—Å–Ω—ã–º –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –Ω–∞–ª–æ–∂–µ–Ω–∏–µ–º.\n",
        "for (x, y, w, h) in final_boxes:\n",
        "    roi = image[y:y+h, x:x+w]\n",
        "    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç 3 –∫–∞–Ω–∞–ª–∞, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ROI –≤ —Ü–≤–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
        "    roi_color = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)\n",
        "    roi_resized = cv2.resize(roi_color, input_size)\n",
        "    roi_normalized = roi_resized.astype('float32') / 255.0\n",
        "    roi_input = np.expand_dims(roi_normalized, axis=0)\n",
        "\n",
        "    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "    prediction = model.predict(roi_input)\n",
        "\n",
        "    # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ–Ω—å—à–µ 0.5, —Å—á–∏—Ç–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç –¥–µ—Ñ–µ–∫—Ç–Ω—ã–º (–∫–ª–∞—Å—Å 0)\n",
        "    if prediction[0][0] < 0.5:\n",
        "        overlay = image_with_overlay.copy()\n",
        "        cv2.rectangle(overlay, (x, y), (x+w, y+h), (0, 0, 255), -1)  # –∑–∞–ª–∏–≤–∫–∞ –∫—Ä–∞—Å–Ω—ã–º\n",
        "        alpha = 0.4  # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏\n",
        "        image_with_overlay = cv2.addWeighted(overlay, alpha, image_with_overlay, 1 - alpha, 0)\n",
        "\n",
        "# 10. –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —á–µ—Ä–µ–∑ matplotlib\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(cv2.cvtColor(image_with_overlay, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.title(\"–°–µ–≥–º–µ–Ω—Ç—ã –∫–ª–∞—Å—Å–∞ 0 (–±–µ–∑ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏—Ö—Å—è –±–æ–∫—Å–æ–≤)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaxl_qALH9jm"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/drive/MyDrive/inp/image_capillar (19).png\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# 2. –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ (CLAHE)\n",
        "# clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "# image = clahe.apply(image)\n",
        "\n",
        "# 3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —à—É–º–∞\n",
        "blurred = cv2.GaussianBlur(image, (3,3), 0)\n",
        "\n",
        "# 4. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü (Canny)\n",
        "edges = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "# 5. –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤\n",
        "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# 6. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç—É—Ä–æ–≤ (—É–¥–∞–ª—è–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã)\n",
        "filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 20]\n",
        "\n",
        "# 7. –û–ø—Ä–µ–¥–µ–ª—è–µ–º bounding boxes (–ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ —Ä–∞–º–∫–∏)\n",
        "padding = 30  # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–º–∫–∏\n",
        "boxes = []\n",
        "\n",
        "for cnt in filtered_contours:\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    x_new = max(0, x - padding)\n",
        "    y_new = max(0, y - padding)\n",
        "    w_new = min(image.shape[1] - x_new, w + 2 * padding)\n",
        "    h_new = min(image.shape[0] - y_new, h + 2 * padding)\n",
        "    boxes.append((x_new, y_new, w_new, h_new))\n",
        "\n",
        "# 8. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º bounding boxes –≤ —Ñ–æ—Ä–º–∞—Ç (x, y) —Ü–µ–Ω—Ç—Ä–∞ + —Ä–∞–∑–º–µ—Ä—ã\n",
        "box_centers = [(x + w // 2, y + h // 2) for x, y, w, h in boxes]\n",
        "box_sizes = [(w, h) for _, _, w, h in boxes]\n",
        "\n",
        "# 9. –ü—Ä–∏–º–µ–Ω—è–µ–º DBSCAN –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –±–ª–∏–∑–∫–∏—Ö –∫–∞–ø–∏–ª–ª—è—Ä–æ–≤\n",
        "X = np.array(boxes)  # –ú–∞—Å—Å–∏–≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Ü–µ–Ω—Ç—Ä–æ–≤ —Ä–∞–º–æ–∫\n",
        "dbscan = DBSCAN(eps=35, min_samples=1).fit(X)  # eps ‚Äî —Ä–∞–¥–∏—É—Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è\n",
        "\n",
        "# 10. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ä–∞–º–æ–∫ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º\n",
        "clustered_boxes = {}\n",
        "for label, ((x, y), (w, h)) in zip(dbscan.labels_, zip(box_centers, box_sizes)):\n",
        "    if label not in clustered_boxes:\n",
        "        clustered_boxes[label] = []\n",
        "    clustered_boxes[label].append((x, y, w, h))\n",
        "\n",
        "# 11. –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ bounding boxes –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞\n",
        "final_boxes = []\n",
        "for cluster in clustered_boxes.values():\n",
        "    x_min = min(x - w // 2 for x, y, w, h in cluster)\n",
        "    y_min = min(y - h // 2 for x, y, w, h in cluster)\n",
        "    x_max = max(x + w // 2 for x, y, w, h in cluster)\n",
        "    y_max = max(y + h // 2 for x, y, w, h in cluster)\n",
        "    final_boxes.append((x_min, y_min, x_max - x_min, y_max - y_min))\n",
        "\n",
        "# 12. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "image_with_boxes = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# 13. –í—ã—Ä–µ–∑–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã\n",
        "segments = []\n",
        "for (x, y, w, h) in final_boxes:\n",
        "    segment = image[y:y+h, x:x+w]\n",
        "    segments.append(segment)\n",
        "    cv2.rectangle(image_with_boxes, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "# 14. –í—ã–≤–æ–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Ç–æ–≥–æ–≤—ã–º–∏ —Ä–∞–º–∫–∞–º–∏\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"–ö–∞–ø–∏–ª–ª—è—Ä—ã –ø–æ—Å–ª–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ DBSCAN\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# 15. –í—ã–≤–æ–¥ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω–æ\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    axes[i].imshow(segments[i], cmap=\"gray\")\n",
        "    axes[i].axis(\"off\")\n",
        "    axes[i].set_title(f\"–ö–∞–ø–∏–ª–ª—è—Ä {i+1}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8JK2cWKgon2"
      },
      "outputs": [],
      "source": [
        "def save_segment(segment, segment_id, output_dir=\"/content/drive/MyDrive/inp/segments19\"):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    segment_filename = f\"{output_dir}/segment_{4122+segment_id}.png\"\n",
        "    cv2.imwrite(segment_filename, segment)  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "\n",
        "segment_id = 1  # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ (–º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞)\n",
        "for segment in segments:\n",
        "    segment = cv2.resize(segment, (64, 64))\n",
        "    save_segment(segment, segment_id)\n",
        "    segment_id += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfC2LTjtiNrk"
      },
      "outputs": [],
      "source": [
        "def write_to_csv(segment_id, label, csv_filename=\"/content/drive/MyDrive/inp/labels19.csv\"):\n",
        "    with open(csv_filename, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([f\"segment_{4122+segment_id}.png\", label])\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "for segment_id in range(1, segment_id+1):\n",
        "    label = \"1\"  # –∏–ª–∏ \"unhealthy\"\n",
        "    write_to_csv(segment_id, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUS6W2kkSnih"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ CSV-—Ñ–∞–π–ª–∞\n",
        "df = pd.read_csv('/content/drive/MyDrive/capillaroscopy/csv/labels.csv')\n",
        "\n",
        "# –ü–æ–¥—Å—á—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ\n",
        "class_counts = df['class'].value_counts()\n",
        "\n",
        "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:\")\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krIob5JZKvMJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bcys2nEJPdXH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/capillaroscopy/csv/labels.csv\")\n",
        "df[\"filepath\"] = df[\"filename\"].apply(lambda x: os.path.join(\"/content/drive/MyDrive/capillaroscopy/data/train\", x))\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df[\"class\"], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"class\"], random_state=42)\n",
        "\n",
        "\n",
        "X_train = np.array(train_df[\"filepath\"])\n",
        "y_train = np.array(train_df[\"class\"])\n",
        "\n",
        "# Oversampling —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤\n",
        "ros = RandomOverSampler(sampling_strategy=\"auto\")  # –ê–≤—Ç–æ-—É—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train.reshape(-1, 1), y_train)\n",
        "\n",
        "# –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
        "train_df_resampled = pd.DataFrame({\"filepath\": X_resampled.flatten(), \"class\": y_resampled})\n",
        "\n",
        "print(f\"Train: {len(train_df_resampled)}, Validation: {len(val_df)}, Test: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "immKjHArSKbg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNnIW37ASVXN"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, rotation_range=30, width_shift_range=0.2, height_shift_range=0.2,\n",
        "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest'\n",
        ")\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)  # –ë–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
        "train_df_resampled[\"class\"] = train_df_resampled[\"class\"].astype(str)\n",
        "val_df[\"class\"] = val_df[\"class\"].astype(str)\n",
        "test_df[\"class\"] = test_df[\"class\"].astype(str)\n",
        "# –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö\n",
        "train_generator = train_datagen.flow_from_dataframe(train_df_resampled, x_col=\"filepath\", y_col=\"class\", target_size=(64, 64),\n",
        "                                                    batch_size=32, class_mode=\"sparse\")\n",
        "val_generator = val_test_datagen.flow_from_dataframe(val_df, x_col=\"filepath\", y_col=\"class\", target_size=(64, 64),\n",
        "                                                     batch_size=32, class_mode=\"sparse\")\n",
        "test_generator = val_test_datagen.flow_from_dataframe(test_df, x_col=\"filepath\", y_col=\"class\", target_size=(64, 64),\n",
        "                                                      batch_size=32, class_mode=\"sparse\", shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seLY97b4SZTA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuJh_YypSb6V"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º EfficientNetB0 –±–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è\n",
        "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(64, 64, 3))\n",
        "# base_model.trainable = False  # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞\n",
        "for layer in base_model.layers[:-10]:  # –ú–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –æ–±—É—á–∞–µ–º—ã–º–∏\n",
        "    layer.trainable = False\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º —Å–≤–æ–∏ —Å–ª–æ–∏\n",
        "# x = GlobalAveragePooling2D()(base_model.output)\n",
        "# x = Dense(128, activation=\"relu\")(x)\n",
        "# x = Dense(3, activation=\"softmax\")(x)  # 3 –∫–ª–∞—Å—Å–∞\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)  # –£–º–µ–Ω—å—à–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(3, activation=\"softmax\")(x)  # 3 –∫–ª–∞—Å—Å–∞\n",
        "\n",
        "\n",
        "# –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "#class_weights = compute_class_weight(\"balanced\", classes=np.unique(train_df[\"class\"]), y=train_df[\"class\"])\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å\n",
        "#class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=20, steps_per_epoch=len(train_generator),\n",
        "                    validation_steps=len(val_generator))\n",
        "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —É—á–µ—Ç–æ–º –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤\n",
        "#history = model.fit(train_generator, validation_data=val_generator, epochs=20,\n",
        "#                    steps_per_epoch=len(train_generator), validation_steps=len(val_generator),\n",
        "#                   class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGLgCpLmSfkl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu6DLdDuSiBM"
      },
      "outputs": [],
      "source": [
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc, \"b-\", label=\"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏\")\n",
        "plt.plot(epochs, val_acc, \"r-\", label=\"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\")\n",
        "plt.xlabel(\"–≠–ø–æ—Ö–∏\")\n",
        "plt.ylabel(\"–¢–æ—á–Ω–æ—Å—Ç—å\")\n",
        "plt.legend()\n",
        "plt.title(\"–ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏\")\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, \"b-\", label=\"–ü–æ—Ç–µ—Ä–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏\")\n",
        "plt.plot(epochs, val_loss, \"r-\", label=\"–ü–æ—Ç–µ—Ä–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\")\n",
        "plt.xlabel(\"–≠–ø–æ—Ö–∏\")\n",
        "plt.ylabel(\"–ü–æ—Ç–µ—Ä–∏\")\n",
        "plt.legend()\n",
        "plt.title(\"–ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG_YbnJtZ0kR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZYR2Tz1SkwW"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPIIyHMKVdkE"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/capillaroscopy/capillaries_classifier1.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui3OEJjUYcy2"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\"/content/drive/MyDrive/capillaroscopy/csv/labels.csv\")\n",
        "test_class_0_df = test_df[test_df[\"class\"] == 1].copy()\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º\n",
        "test_class_0_df[\"filepath\"] = test_class_0_df[\"filename\"].apply(lambda x: os.path.join(\"/content/drive/MyDrive/capillaroscopy/data/train/\", x))\n",
        "\n",
        "print(f\"–ù–∞–π–¥–µ–Ω–æ {len(test_class_0_df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–ª–∞—Å—Å–∞ 0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HEtu1SIZReF"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–ª–∞—Å—Å–∞ 0\n",
        "test_class_0_generator = test_datagen.flow_from_dataframe(\n",
        "    test_class_0_df, x_col=\"filepath\", y_col=None, target_size=(64, 64),\n",
        "    batch_size=32, class_mode=None, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBHXRgUiZj0O"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APWEvwMNZXOW"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_class_0_generator)\n",
        "\n",
        "# –ë–µ—Ä–µ–º –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "for filename, pred in zip(test_class_0_df[\"filename\"], predicted_classes):\n",
        "    print(f\"{filename}: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å {pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FPn7IhZpLGo"
      },
      "source": [
        "–°–æ–∑–¥–∞–¥–∏–º –∫–∞—Å—Ç–æ–º–Ω—É—é CNN —Å 0:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0O98SLipPhO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCLKNuU6pSZK"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    # 1-–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    # 2-–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    # 3-–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    # 4-–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫ (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ)\n",
        "    Conv2D(256, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(3, activation='softmax')  # 3 –∫–ª–∞—Å—Å–∞\n",
        "])\n",
        "\n",
        "    # Flatten(),\n",
        "\n",
        "#     # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏\n",
        "#     Dense(256, activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(128, activation='relu'),\n",
        "#     Dropout(0.4),\n",
        "#     Dense(64, activation='relu'),\n",
        "#     Dropout(0.3),\n",
        "#     Dense(3, activation='softmax')  # 3 –∫–ª–∞—Å—Å–∞\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "326SC0S5pUZ1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpb1gFc1pfFL"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N5o_IBhpgR-"
      },
      "outputs": [],
      "source": [
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc, \"b-\", label=\"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏\")\n",
        "plt.plot(epochs, val_acc, \"r-\", label=\"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\")\n",
        "plt.xlabel(\"–≠–ø–æ—Ö–∏\")\n",
        "plt.ylabel(\"–¢–æ—á–Ω–æ—Å—Ç—å\")\n",
        "plt.legend()\n",
        "plt.title(\"–ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏\")\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, \"b-\", label=\"–ü–æ—Ç–µ—Ä–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏\")\n",
        "plt.plot(epochs, val_loss, \"r-\", label=\"–ü–æ—Ç–µ—Ä–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\")\n",
        "plt.xlabel(\"–≠–ø–æ—Ö–∏\")\n",
        "plt.ylabel(\"–ü–æ—Ç–µ—Ä–∏\")\n",
        "plt.legend()\n",
        "plt.title(\"–ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fl2i_v5Rq5T4"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbWfA30V5nyD"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions = model.predict(test_generator)\n",
        "\n",
        "\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"Filename\": filenames,\n",
        "    \"True Class\": true_classes,\n",
        "    \"Predicted Class\": predicted_classes\n",
        "})\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ CSV\n",
        "df.to_csv(\"/content/drive/MyDrive/capillaroscopy/capillaries_classifier2.csv\", index=False)\n",
        "print(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ predictions_with_filenames.csv\")\n",
        "\n",
        "# –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KY87X7JarINj"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/capillaroscopy/capillaries_classifier4.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itx70Sp8rIwI"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\"/content/drive/MyDrive/capillaroscopy/csv/labels.csv\")\n",
        "test_class_0_df = test_df[test_df[\"class\"] == 1].copy()\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º\n",
        "test_class_0_df[\"filepath\"] = test_class_0_df[\"filename\"].apply(lambda x: os.path.join(\"/content/drive/MyDrive/capillaroscopy/data/train/\", x))\n",
        "\n",
        "print(f\"–ù–∞–π–¥–µ–Ω–æ {len(test_class_0_df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–ª–∞—Å—Å–∞ 0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMZPc0WlrTVk"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–ª–∞—Å—Å–∞ 0\n",
        "test_class_0_generator = test_datagen.flow_from_dataframe(\n",
        "    test_class_0_df, x_col=\"filepath\", y_col=None, target_size=(64, 64),\n",
        "    batch_size=32, class_mode=None, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_lR3XpHrZS_"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_class_0_generator)\n",
        "\n",
        "# –ë–µ—Ä–µ–º –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "for filename, pred in zip(test_class_0_df[\"filename\"], predicted_classes):\n",
        "    print(f\"{filename}: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å {pred}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHcrUiz4qFTQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBaHead4p_Ol"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuwGFPC1olV6"
      },
      "source": [
        "–î–µ–ª–∏–º –≤—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ 64–•64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ReWYauS2Pjb"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/drive/MyDrive/inp/image_capillar (15).png\"  # –£–∫–∞–∂–∏ —Å–≤–æ–π –ø—É—Ç—å\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥—Ä—É–∑–∫—É\n",
        "if image is None:\n",
        "    raise ValueError(\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\")\n",
        "\n",
        "# –†–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "h, w, _ = image.shape\n",
        "grid_size = 15  # 15x15 = 225 —á–∞—Å—Ç–µ–π\n",
        "\n",
        "# –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞\n",
        "tile_h = h // grid_size\n",
        "tile_w = w // grid_size\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
        "output_folder = \"output_tiles\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# –†–∞–∑–±–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã\n",
        "tile_counter = 0\n",
        "tiles = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 5 —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\n",
        "\n",
        "for i in range(grid_size):\n",
        "    for j in range(grid_size):\n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–µ–∫—É—â–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞\n",
        "        x_start = j * tile_w\n",
        "        y_start = i * tile_h\n",
        "        x_end = x_start + tile_w\n",
        "        y_end = y_start + tile_h\n",
        "\n",
        "        # –í—ã—Ä–µ–∑–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç\n",
        "        tile = image[y_start:y_end, x_start:x_end]\n",
        "\n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç\n",
        "        tile_filename = os.path.join(output_folder, f\"tile_{tile_counter:03d}.png\")\n",
        "        cv2.imwrite(tile_filename, tile)\n",
        "\n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–æ–∫\n",
        "        if tile_counter < 15:\n",
        "            tiles.append(cv2.cvtColor(tile, cv2.COLOR_BGR2RGB))  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR ‚Üí RGB –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "\n",
        "        tile_counter += 1\n",
        "\n",
        "fig, axes = plt.subplots(1, 15, figsize=(15, 15))\n",
        "for idx, ax in enumerate(axes):\n",
        "    ax.imshow(tiles[idx])\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(f\"–§—Ä–∞–≥–º–µ–Ω—Ç {idx+1}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aBCLWBwp0FT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å\n",
        "model = load_model(\"/content/drive/MyDrive/capillaroscopy/capillaries_classifier2_func.keras\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbk_DfoJrCup"
      },
      "outputs": [],
      "source": [
        "# –ü–∞–ø–∫–∞ —Å —Ä–∞–∑—Ä–µ–∑–∞–Ω–Ω—ã–º–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏\n",
        "tile_folder = \"output_tiles\"\n",
        "tile_size = (64, 64)  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞ –º–æ–¥–µ–ª—å\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø–∞–ø–∫–∏\n",
        "image_files = sorted(os.listdir(tile_folder))  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏\n",
        "tiles = []\n",
        "\n",
        "for filename in image_files:\n",
        "    img_path = os.path.join(tile_folder, filename)\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    if img is None:\n",
        "        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è\n",
        "\n",
        "    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–¥ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏\n",
        "    img = cv2.resize(img, tile_size)\n",
        "\n",
        "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π –ø–∏–∫—Å–µ–ª–µ–π\n",
        "    img = img / 255.0\n",
        "\n",
        "    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫\n",
        "    tiles.append(img)\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy-–º–∞—Å—Å–∏–≤ –¥–ª—è –ø–æ–¥–∞—á–∏ –≤ –º–æ–¥–µ–ª—å\n",
        "tiles = np.array(tiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI1sQJeQrXgW"
      },
      "outputs": [],
      "source": [
        "# –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "predictions = model.predict(tiles)\n",
        "\n",
        "# –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 10 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "for i in range(10):\n",
        "    print(f\"üìå –§–∞–π–ª: {image_files[i]} ‚Üí –ö–ª–∞—Å—Å: {predicted_classes[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCybaKRerec6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"Filename\": image_files,\n",
        "    \"Predicted Class\": predicted_classes\n",
        "})\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/capillaroscopy/tile_predictions.csv\", index=False)\n",
        "print(\"üìÅ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ tile_predictions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNf4a9dRshX0"
      },
      "outputs": [],
      "source": [
        "original_image = cv2.imread(image_path)\n",
        "\n",
        "if original_image is None:\n",
        "    raise ValueError(\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\")\n",
        "\n",
        "h, w, _ = original_image.shape  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "\n",
        "# üîπ –ü–∞–ø–∫–∞ —Å —Ä–∞–∑—Ä–µ–∑–∞–Ω–Ω—ã–º–∏ —á–∞—Å—Ç—è–º–∏\n",
        "tile_folder = \"output_tiles\"\n",
        "tile_size = (64, 64)  # –†–∞–∑–º–µ—Ä, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å\n",
        "grid_size = 15 # –†–∞–∑–±–∏–µ–Ω–∏–µ 15x15 = 225 —á–∞—Å—Ç–µ–π\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "image_files = sorted(os.listdir(tile_folder))\n",
        "tiles = []\n",
        "\n",
        "for filename in image_files:\n",
        "    img_path = os.path.join(tile_folder, filename)\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–¥ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏\n",
        "    img = cv2.resize(img, tile_size)\n",
        "    img = img / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "    tiles.append(img)\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy-–º–∞—Å—Å–∏–≤\n",
        "tiles = np.array(tiles)\n",
        "\n",
        "# üîπ –ü—Ä–æ–≥–æ–Ω—è–µ–º —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å\n",
        "predictions = model.predict(tiles)\n",
        "predicted_classes = np.argmax(predictions, axis=1)  # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å—ã\n",
        "\n",
        "# üîπ –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é\n",
        "tile_h = h // grid_size\n",
        "tile_w = w // grid_size\n",
        "\n",
        "# üî• –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –æ–±–ª–∞—Å—Ç–µ–π –∫–ª–∞—Å—Å–∞ 0\n",
        "mask = np.zeros_like(original_image, dtype=np.uint8)\n",
        "\n",
        "tile_counter = 0\n",
        "for i in range(grid_size):\n",
        "    for j in range(grid_size):\n",
        "        x_start, y_start = j * tile_w, i * tile_h\n",
        "        x_end, y_end = x_start + tile_w, y_start + tile_h\n",
        "\n",
        "        if predicted_classes[tile_counter] == 0:  # –ï—Å–ª–∏ –∫–ª–∞—Å—Å 0, —Ä–∏—Å—É–µ–º –∫—Ä–∞—Å–Ω—É—é –º–∞—Å–∫—É\n",
        "            cv2.rectangle(mask, (x_start, y_start), (x_end, y_end), (0, 0, 255), -1)  # –ö—Ä–∞—Å–Ω—ã–π\n",
        "        elif predicted_classes[tile_counter] == 2:\n",
        "             cv2.rectangle(mask, (x_start, y_start), (x_end, y_end), (0, 255, 255), -1)\n",
        "\n",
        "        tile_counter += 1\n",
        "\n",
        "# üîπ –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Å–∫—É –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é\n",
        "alpha = 0.4  # –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å\n",
        "highlighted_image = cv2.addWeighted(original_image, 1, mask, alpha, 0)\n",
        "\n",
        "# üìå –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cv2.cvtColor(highlighted_image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"–í—ã–¥–µ–ª–µ–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∫–ª–∞—Å—Å–∞ 0\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pspCWAL9ZlW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/capillaroscopy/csv/labels.csv\")\n",
        "\n",
        "# –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è 2 –≤ —Å—Ç–æ–ª–±—Ü–µ \"class\" –Ω–∞ 0\n",
        "df.loc[df[\"class\"] == 2, \"class\"] = 1\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∏—Å—Ö–æ–¥–Ω—ã–π CSV (–º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª)\n",
        "df.to_csv(\"/content/drive/MyDrive/capillaroscopy/csv/labels_three.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tqJBkTOQSyZW4oyLArpd6guPpT4ddfUE",
      "authorship_tag": "ABX9TyMAQ46M0jRBVjjv7s6w1K+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}